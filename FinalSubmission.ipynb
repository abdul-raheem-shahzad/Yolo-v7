{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> **YVPD: YOLO Visual Pollution Detection System**</center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction </br>\n",
    "Visual pollution refers to objects or activities in the environment that negatively impact its aesthetic appeals, such as graffiti, billboards, unkept facades, and cluttered sidewalks. These types of pollution can decrease an area's value, distract drivers, and affect the quality of life for residents. It is crucial for cities to take action to combat visual pollution for the benefit of both residents and visitors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement </br>\n",
    "Visual pollution in urban areas is a growing concern affecting residents' quality of life. We're on a mission to revolutionize the way we measure and address it, by simulating human learning to create a \"visual pollution score/index\" using cutting-edge technology and data from a fleet of vehicles in KSA. \t\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE:** A detailed report has been submitted separately on SDAIA platform. This notebook contains the related code and info. The manual work done in excel is also mentioned in the specified report."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import torch\n",
    "from IPython.display import Image  \n",
    "import os \n",
    "import random\n",
    "import shutil\n",
    "import PIL\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv into df\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading unique class names \n",
    "print(df['name'].unique())\n",
    "print(df.name.unique())\n",
    "\n",
    "# Convert to List\n",
    "print(df.name.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making separate folders to store training and validation data\n",
    "!mkdir training val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making image and label folders inside training and validation folders\n",
    "!mkdir training/images training/labels val/images val/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting labels into yolo format\n",
    "# Creating the list of images from the excel sheet\n",
    "imgs = df['image_path'].unique().tolist()\n",
    "# Loop through each of the image\n",
    "for img in imgs:\n",
    "    boundingDetails = []\n",
    "    # First get the bounding box information for a particular image from the excel sheet\n",
    "    boundingInfo = df.loc[df.image_path == img,:]\n",
    "    # Loop through each row of the details\n",
    "    for idx, row in boundingInfo.iterrows():\n",
    "        # Get the class Id for the row\n",
    "        class_id =row[\"class\"]\n",
    "        # Convert the bounding box info into the format for YOLOV5\n",
    "        # Get the width\n",
    "        bb_width = row['xmax'] - row['xmin']\n",
    "        # Get the height\n",
    "        bb_height = row['ymax'] - row['ymin']\n",
    "        # Get the centre coordinates\n",
    "        bb_xcentre = (row['xmin'] + row['xmax'])/2\n",
    "        bb_ycentre = (row['ymin'] + row['ymax'])/2\n",
    "        # Normalise the coordinates by diving by width and height\n",
    "\n",
    "        bb_xcentre /= row['width'] \n",
    "        bb_ycentre /= row['height'] \n",
    "        bb_width    /= row['width'] \n",
    "        bb_height   /= row['height']  \n",
    "        #Append details in the list \n",
    "        boundingDetails.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, bb_xcentre, bb_ycentre, bb_width, bb_height))\n",
    "    # Create the file name to save this info     \n",
    "    file_name = os.path.join(\"labels\", img.split(\".\")[0] + \".txt\")\n",
    "    # Save the annotation to disk\n",
    "    print(\"\\n\".join(boundingDetails), file= open(file_name, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading all text files and storing them in a varaiable\n",
    "annotations = glob.glob('labels' +'/*.txt')\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of images from its folder\n",
    "imagePath = 'C:/smartathon/dataset/images'\n",
    "images = glob.glob(imagePath + '/*.jpg')\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the annotations and images and the prepare the train and validation sets\n",
    "images.sort()\n",
    "annotations.sort()\n",
    " \n",
    "# Split the dataset into train-valid splits \n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function to copy images to destination folder\n",
    "def move_files_to_folder(list_of_files, destination_folder):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            shutil.copy(f, destination_folder)\n",
    "        except:\n",
    "            print(f)\n",
    "            assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the splits into the respective folders\n",
    "move_files_to_folder(train_images, 'training/images')\n",
    "move_files_to_folder(val_images, 'val/images')\n",
    "move_files_to_folder(train_annotations, 'training/labels')\n",
    "move_files_to_folder(val_annotations, 'val/labels')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the conversion of labels from pascalvoc to yolo format is complete, now the model has to be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cloning yolov7 into local directory \n",
    "!git clone https://github.com/WongKinYiu/yolov7.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing current directory to yolov7 folder\n",
    "cd C:\\smartathon\\dataset\\images\\yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the pre-trained weights file\n",
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the yolov7 model on 200 epochs with 8 workers, batch size 16 and image size (640 px)\n",
    "!python train.py --workers 8 --device 0 --batch-size 16 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights 'yolov7_training.pt' --name yolov7_custom1 --hyp data/hyp.scratch.custom.yaml --epoch 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model has been trained, it is later applied on unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model is being tested with the best trained weights\n",
    "!python detect.py --weights best.pt --source test_images --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to convert normalized predicted labels to nonnormalized format\n",
    "def yolo_to_pascal_voc(x_center, y_center, w, h,  image_w, image_h):\n",
    "    w = w * image_w\n",
    "    h = h * image_h\n",
    "    x1 = ((2 * x_center * image_w) - w)/2\n",
    "    y1 = ((2 * y_center * image_h) - h)/2\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "#converting labels from yolo format to pascalvoc format and adding images' paths as well.\n",
    "for annotation in annotations:\n",
    "    with open(annotation, 'r') as f:\n",
    "        content = f.readlines()\n",
    "        new_file_name = annotation.replace(\".txt\", \"_pascal_voc.txt\") # new file name with different format\n",
    "        with open(new_file_name, 'w') as new_f:\n",
    "            for line in content:\n",
    "                class_name, x_center, y_center, w, h = line.strip().split()\n",
    "                x1, y1, x2, y2 = yolo_to_pascal_voc(float(x_center), float(y_center), float(w), float(h),1920, 1080)\n",
    "                new_f.write(annotation + \" \" + class_name + \" \" + str(x1) + \" \" + str(y1) + \" \" + str(x2) + \" \" + str(y2) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now converting labels from txt to csv format\n",
    "folder_path = 'dest'\n",
    "csv_file = 'dest2.csv'\n",
    "\n",
    "# Get list of all text files in the folder\n",
    "txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "# Create a list to store the data from the text files\n",
    "data = []\n",
    "\n",
    "# Iterate through each text file\n",
    "for txt_file in txt_files:\n",
    "    with open(os.path.join(folder_path, txt_file), 'r') as f:\n",
    "        # Read each line of the text file\n",
    "        lines = f.readlines()\n",
    "        # Iterate through each line\n",
    "        for line in lines:\n",
    "            # Split the line by space\n",
    "            words = line.split(\" \")\n",
    "            # Append the file name and words as separate columns in the data list\n",
    "            data.append([txt_file]+words)\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['File Name']+['word_'+str(i) for i in range(len(words))])\n",
    "    writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now adding the name column in csv file in accordance to the class column\n",
    "\n",
    "df107=df10\n",
    "\n",
    "# Create a dictionary of class-name mapping\n",
    "class_name_mapping = {'0': 'GRAFFITI', '1': 'FADED_SIGNAGE', '2': 'POTHOLES', '3': 'GARBAGE', '4': 'CONSTRUCTION_ROAD', '5': 'BROKEN_SIGNAGE', '6':'BAD_STREETLIGHT','7':'BAD_BILLBOARD','8':'SAND_ON_ROAD','9':'CLUTTER_SIDEWALK','10':'UNKEPT_FACADE'}\n",
    "\n",
    "# Add a new column 'name' and assign the corresponding name from the dictionary\n",
    "df107['name'] = df107['class'].map(class_name_mapping)\n",
    "\n",
    "# write the changes back to the file\n",
    "df107.to_csv('example1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As the files have to be submitted in specific formats, the columns in csv file have been reordered adn renamed. \n",
    "\n",
    "# specify the new order of columns\n",
    "new_column_order = ['class', 'image_path', 'name', 'x_max', 'x_min', 'y_max', 'y_min']\n",
    "\n",
    "# reorder the columns\n",
    "df108 = df108[new_column_order]\n",
    "\n",
    "# write the changes back to the file\n",
    "df108.to_csv('submission.csv', index=False)\n",
    "\n",
    "#renaming the column names\n",
    "df108 = df108.rename(columns={'x_max': 'xmax', 'y_max':'ymax', 'x_min':'xmin', 'y_min':'ymin'})\n",
    "\n",
    "#The values in the numerical columns have been rounded \n",
    "# columns to truncate decimal values\n",
    "columns_to_truncate = ['x_min', 'y_min', 'x_max', 'y_max']\n",
    "\n",
    "# truncate decimal values in columns \n",
    "df105[columns_to_truncate] = df105[columns_to_truncate].apply(lambda x: x.apply(lambda x: int(x)))\n",
    "\n",
    "# write the changes back to the file\n",
    "df105.to_csv('example.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the results and related information have been mentioned in the linked pdf report, submmitted on SDAIA platform. The csv file (finalsubmission.csv) has also been submitted for evaluation purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19384c391d524043d5f9dcfabe2b14a4b570ba0b0cb5648ae14776438c128291"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
